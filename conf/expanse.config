//-- * https://www.sdsc.edu/systems/expanse/user_guide.html
//-- * max running jobs on gpu-shared is 24


// -- * Enable singularity stuff
singularity.enabled     = true
singularity.autoMounts  = true
conda.enabled           = false
docker.enabled          = false
podman.enabled          = false
shifter.enabled         = false
charliecloud.enabled    = false
apptainer.enabled       = false


// Change custom workDir
workDir = "${params.output_workdir} ?: ${launchDir}"

executor {
    queueSize = 22
}





process {
    executor = 'slurm'
    maxRetries = 1
    pollInterval = '2 min'
    queueStatInterval = '5 min'
    submitRateLimit = '6/1min'
    retry.maxAttempts = 1

    clusterOptions = ' --export=ALL --nodes=1 --ntasks-per-node=1 -t 09:00:00 -A $params.project '

    scratch = '/scratch/$USER/job_$SLURM_JOB_ID'

//-- * This makes processes associated with low_cpu label to use only 1 core and 512MB ram

//-- * Will run on XEON GOLD 40 core node with 4 NVIDIA V100, 384 GB RAM, on expanse there are 52 nodes
withLabel:gpu_task {
    errorStrategy = 'retry'
    memory = {8.GB * task.attempt}
    cpus = 2
    time = {10.min * task.attempt}
    maxRetries = { task.exitStatus >= 100 ? 4 : 1 }
    queue = 'gpu-shared'
    clusterOptions = " --export=ALL --nodes=1  --ntasks-per-node=1   -A ${params.project} --gpus=1"

}

withLabel:cpu_task {
    errorStrategy = 'retry'
    memory = {8.GB * task.attempt}
    cpus = 8
    time = {20.min * task.attempt}
    maxRetries = { task.exitStatus >= 100 ? 4 : 1 }
    queue = 'shared'
    clusterOptions = " --export=ALL --nodes=1  --ntasks-per-node=1   -A ${params.project}"

}


withLabel:low_cpu{
    errorStrategy = 'retry'
    memory = {2.GB * task.attempt}
    cpus = 4
    time = {10.min * task.attempt}
    maxRetries = { task.exitStatus >= 100 ? 4 : 1 }
    queue = 'shared'
    clusterOptions = " --export=ALL --nodes=1  --ntasks-per-node=1 -A ${params.project}"

}





}
timeline.enabled = true
report.enabled = true
report.overwrite = true

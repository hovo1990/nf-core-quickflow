This is not effective on HPC schedulers,
need to change approach otherwise it is gonna take an eternity to take get a queue


1. maybe run python script using mpire to parallize conformer generation
2. but the biggest question is how does one track the changes then

I have a csv as input, which then starts running individual processes, is it possible to bundle the separate tasks into one process so it runs only on one node on SLURM HPC cluster, and yet cache the results


I have a CSV file as input that triggers multiple individual processes. Is it possible to bundle these tasks into a single process so that they run on a single node in an SLURM HPC cluster while also caching the results for efficiency?